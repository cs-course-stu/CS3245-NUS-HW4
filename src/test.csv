"document_id","title","content","date_posted","court"
"0","doc zero ","Refiner can tokenize query strings into terms and tokens","",""
"1","doc one  ","refiner tokenize strings terms tokens","",""
"2","doc two  ","can query into and","",""
"3","doc three","refiner query terms","",""
"4","doc four ","can strings and","",""
"5","doc five ","Query Computer Science","",""
"6","doc six  ","tokenize into tokens","",""
"7","doc seven","refiner string","",""
"8","doc eight","can can can can can can","",""
"9","doc nine ","tokens tokens tokens","",""
